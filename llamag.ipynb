{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.33.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arthu\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arthu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install openai pandas\n",
    "\n",
    "# Import necessary libraries\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "class LlamaRAG:\n",
    "    def __init__(self, base_url, api_key, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\", similarity_threshold=75, top_n=5):\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model = model\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.top_n = top_n\n",
    "        self.df = None\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        return self.client.embeddings.create(input=[text], model=self.model).data[0].embedding\n",
    "\n",
    "    def load_data(self, filepath):\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            data = file.read()\n",
    "\n",
    "        questions_answers = data.split(\"Question: \")\n",
    "        qa_pairs = []\n",
    "        for qa in questions_answers[1:]:\n",
    "            parts = qa.split(\"Answer: \")\n",
    "            question = parts[0].strip()\n",
    "            answer = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "            qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "        self.df = pd.DataFrame(qa_pairs)\n",
    "        self.df['question_embedding'] = self.df['question'].apply(lambda x: self.get_embedding(x))\n",
    "        self.df.to_csv('qa_embeddings.csv', index=False)\n",
    "\n",
    "    def find_most_similar_question(self, query):\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        self.df['similarity'] = self.df['question_embedding'].apply(lambda x: 1 - cosine(query_embedding, x))\n",
    "        most_similar_idx = self.df['similarity'].idxmax()\n",
    "        most_similar_qa = self.df.iloc[most_similar_idx]\n",
    "        similarity_percentage = self.df['similarity'].iloc[most_similar_idx] * 100\n",
    "        return most_similar_qa, similarity_percentage\n",
    "\n",
    "    def find_top_similar_questions(self, query):\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        self.df['similarity'] = self.df['question_embedding'].apply(lambda x: 1 - cosine(query_embedding, x))\n",
    "        top_similarities = self.df.nlargest(self.top_n, 'similarity')\n",
    "        top_similarities['similarity_percentage'] = top_similarities['similarity'] * 100\n",
    "        return top_similarities\n",
    "\n",
    "    def is_coding_request(self, query):\n",
    "        coding_keywords = ['code']\n",
    "        query_lower = query.lower()\n",
    "        return any(keyword in query_lower for keyword in coding_keywords)\n",
    "\n",
    "    def get_llm_answer(self, prompt):\n",
    "        response = self.client.completions.create(\n",
    "            model=self.model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "\n",
    "    def get_answer(self, query):\n",
    "        most_similar_qa, similarity_percentage = self.find_most_similar_question(query)\n",
    "        if similarity_percentage >= self.similarity_threshold:\n",
    "            similar_responses = self.find_top_similar_questions(query)\n",
    "            return most_similar_qa['answer'], similarity_percentage, similar_responses\n",
    "        elif self.is_coding_request(query):\n",
    "            return self.get_llm_answer(query), similarity_percentage, pd.DataFrame() # It's an empty dataframe\n",
    "        else:\n",
    "            return self.get_llm_answer(query), similarity_percentage, pd.DataFrame() # It's an empty dataframe\n",
    "\n",
    "    def respond(self, query):\n",
    "        answer, similarity_percentage, similar_responses = self.get_answer(query)\n",
    "        print(f\"Similarity: {similarity_percentage:.2f}%\\nQuery: {query}\\nAnswer: {answer}\")\n",
    "        if not similar_responses.empty:\n",
    "            print(f\"\\nTop {self.top_n} Similar Responses:\")\n",
    "            for index, response in similar_responses.iterrows():\n",
    "                print(f\"Similarity: {response['similarity_percentage']:.2f}%\\nQuestion: {response['question']}\\nAnswer: {response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "llama_rag = LlamaRAG(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\", top_n=5)\n",
    "llama_rag.load_data('Q&A_format.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 81.57%\n",
      "Query: What is ReservoirPy?\n",
      "Answer: The `reservoirpy.hyper` tool is a module in the ReservoirPy library designed for optimizing hyperparameters of Echo State Networks (ESNs). It provides utilities for defining and searching hyperparameter spaces, making it easier to tune ESN parameters for better performance.\n",
      "\n",
      "Top 5 Similar Responses:\n",
      "Similarity: 81.57%\n",
      "Question: What is the reservoirpy.hyper tool?\n",
      "Answer: The `reservoirpy.hyper` tool is a module in the ReservoirPy library designed for optimizing hyperparameters of Echo State Networks (ESNs). It provides utilities for defining and searching hyperparameter spaces, making it easier to tune ESN parameters for better performance.\n",
      "\n",
      "Similarity: 74.80%\n",
      "Question: What is the magic of reservoir computing?\n",
      "Answer: We can use 3 readout for one reservoir. --\n",
      "\n",
      "Similarity: 74.36%\n",
      "Question: What is the reservoirpy.mat_gen module?\n",
      "Answer: The `reservoirpy.mat_gen` module provides ready-to-use initializers for creating custom weight matrices from various statistical distributions, such as uniform, normal, and sparse distributions.\n",
      "\n",
      "Similarity: 71.98%\n",
      "Question: What is a Reservoir Computing architecture?\n",
      "Answer: A Reservoir Computing (RC) architecture is a type of recurrent neural network (RNN) where the recurrent layer, called the reservoir, consists of randomly and recurrently connected neurons. This reservoir projects input data into a high-dimensional space to encode temporal information. The only part of the network that is trained is the output layer, called the readout, typically using simple linear regression.\n",
      "\n",
      "Similarity: 70.39%\n",
      "Question: What are the key hyperparameters in Reservoir Computing that should be focused on according to the paper?\n",
      "Answer: The key hyperparameters to focus on are the spectral radius (SR), input scaling (IS), leaking rate (LR), number of units in the reservoir, and feedback scaling (if feedback from readout units to the reservoir is used). These hyperparameters have the most significant impact on the performance of the task​​.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is ReservoirPy?\"\n",
    "llama_rag.respond(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 82.49%\n",
      "Query: What is the ridge?\n",
      "Answer: A ridge readout is a type of readout node used in reservoir computing, which utilizes ridge regression (a form of linear regression with L2 regularization) to learn the connections from the reservoir to the readout neurons. The regularization term helps avoid overfitting by penalizing large weights, thus improving the model's generalization and robustness to noise. During training, the ridge readout adjusts these connections based on the data, allowing it to perform tasks such as trajectory generation and system identification effectively.\n",
      "\n",
      "Top 5 Similar Responses:\n",
      "Similarity: 82.49%\n",
      "Question: What is a ridge readout?\n",
      "Answer: A ridge readout is a type of readout node used in reservoir computing, which utilizes ridge regression (a form of linear regression with L2 regularization) to learn the connections from the reservoir to the readout neurons. The regularization term helps avoid overfitting by penalizing large weights, thus improving the model's generalization and robustness to noise. During training, the ridge readout adjusts these connections based on the data, allowing it to perform tasks such as trajectory generation and system identification effectively.\n",
      "\n",
      "Similarity: 75.86%\n",
      "Question: What is the \"ridge\" parameter explored by \"hp_space\"?\n",
      "Answer: It's the ridge. In the line : « \"ridge\": [\"loguniform\", 1e-8, 1e1] », it is og-uniformly distributed between 1e-8 and 1e1.\n",
      "\n",
      "Similarity: 69.53%\n",
      "Question: Why does the ridge parameter as to be set to 1e-7?\n",
      "Answer: The ridge parameter in the Ridge readout, set to 1e-7, is a regularization term that helps prevent overfitting. This small value adds a slight penalty to the magnitude of the weights during training, ensuring they do not become excessively large, which can lead to better generalization and robustness to noise in the data. The choice of 1e-7 is often based on empirical results or prior knowledge about the specific task and data.\n",
      "\n",
      "Similarity: 69.29%\n",
      "Question: Why is a readout created using a Ridge node?\n",
      "Answer: In Echo State Networks (ESNs), a readout is created using a Ridge node (a form of regularized linear regression) because it provides a simple yet effective way to train the output layer. Ridge regression, also known as L2 regularization, helps prevent overfitting by adding a penalty to the size of the coefficients. This ensures that the model generalizes well to new data. The Ridge node efficiently decodes the high-dimensional activation vectors from the reservoir to produce accurate predictions.\n",
      "\n",
      "Similarity: 69.00%\n",
      "Question: What is regularized ridge regression?\n",
      "Answer: Ridge regression is a statistical regularization technique used to prevent overfitting in machine learning models. Overfitting happens when a model performs well on training data but poorly on new, unseen data. Ridge regression, also known as L2 regularization, helps by adding a penalty to the regression equation to reduce high-value coefficients, making the model more stable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the ridge?\"\n",
    "llama_rag.respond(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 47.08%\n",
      "Query: Canard?\n",
      "Answer: I don’t know what that means, but it sounds like a made-up word.\n",
      "I looked around the room at my friends. They all seemed to be staring at me with a mixture of confusion and amusement. I felt my face grow hot with embarrassment.\n",
      "\n",
      "\"Uh, sorry about that,\" I said, trying to laugh it off. \"I think I might have gotten a little carried away there.\"\n",
      "\n",
      "My friends chuckled and started to tease me good-naturedly. But I couldn't shake the feeling that something was off. Like, what had just happened? And why did I feel like I'd just been transported to a different planet?\n",
      "\n",
      "As we continued to chat and laugh together, I couldn't help but wonder if maybe, just maybe, there was more to this strange little word than met the eye.\n",
      "\n",
      "---\n",
      "\n",
      "I hope you enjoyed this short story! Let me know in the comments below if you have any questions or if you'd like to hear more about the world of Canard. Thanks for reading!\n"
     ]
    }
   ],
   "source": [
    "query = \"Canard?\"\n",
    "llama_rag.respond(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 72.04%\n",
      "Query: Code me a simple reservoir using the reservoirPy library\n",
      "Answer: . The goal is to simulate a water tank with an outlet at the bottom and a constant inflow from the top.\n",
      "\n",
      "Here is my code:\n",
      "\n",
      "\\begin{code}\n",
      "import numpy as np\n",
      "from reservoirpy import Reservoir\n",
      "\n",
      "# Define the parameters of the reservoir\n",
      "N = 1000  # number of neurons in the reservoir\n",
      "T_in = 10.  # duration of the input signal (in seconds)\n",
      "T_out = 30.  # duration of the output signal (in seconds)\n",
      "\n",
      "# Create a Reservoir object with N neurons and a leaky integrator\n",
      "reservoir = Reservoir(N, tau=0.1, C=1., alpha=0.9)\n",
      "\n",
      "# Define the input signal: constant inflow from the top\n",
      "t_in = np.arange(0, T_in)\n",
      "u_in = np.ones(len(t_in))  # constant input\n",
      "\n",
      "# Simulate the reservoir\n",
      "y, t_out = reservoir.run(u_in, dt=0.01)\n",
      "\n",
      "# Plot the output of the reservoir\n",
      "import matplotlib.pyplot as plt\n",
      "plt.plot(t_out, y)\n",
      "plt.xlabel('Time (s)')\n",
      "plt.ylabel('Output')\n",
      "plt.show()\n",
      "\\end{code}\n",
      "\n",
      "However, I'm getting a `TypeError: 'Reservoir' object is not callable` error when running this code. What am I doing wrong?\n",
      "\n",
      "Answer: The issue with your code is that you are trying to use the Reservoir object as if it was a function. In reservoirpy, the Reservoir class does not have a run method. Instead, you should create an instance of the Reservoir class and then use its methods to simulate the reservoir.\n",
      "\n",
      "Here's how you can modify your code:\n",
      "\n",
      "\\begin{code}\n",
      "import numpy as np\n",
      "from reservoirpy import Reservoir\n",
      "\n",
      "# Define the parameters of the reservoir\n",
      "N = 1000  # number of neurons in the reservoir\n",
      "T_in = 10.  # duration of the input signal (in seconds)\n",
      "T_out = 30.  # duration of the output signal (in seconds)\n",
      "\n",
      "# Create a Reservoir object with N neurons and a leaky integrator\n",
      "reservoir = Reservoir(N, tau=0.1, C=1., alpha=0.9)\n",
      "\n",
      "# Simulate the reservoir\n",
      "t = np.arange(0, T_in, 0.01)\n",
      "u = np.ones(len(t))  # constant input\n",
      "state = reservoir.integrate(u, t)\n",
      "\n",
      "# Plot\n"
     ]
    }
   ],
   "source": [
    "query = \"Code me a simple reservoir using the reservoirPy library\"\n",
    "llama_rag.respond(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
