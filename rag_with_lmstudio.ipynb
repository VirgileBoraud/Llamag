{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Unexpected endpoint or method. (POST /v1)'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open('Q&A_format.md', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Manually split the document based on headers\n",
    "questions_answers = data.split(\"Question: \")\n",
    "\n",
    "# Prepare the data for RAG\n",
    "rag_data = []\n",
    "for qa in questions_answers:\n",
    "    if qa.strip():  # Ignore any empty strings\n",
    "        question, *answer = qa.split(\"Answer: \")\n",
    "        if answer:\n",
    "            rag_data.append({\n",
    "                'question': question.strip(),\n",
    "                'answer': answer[0].strip()\n",
    "            })\n",
    "\n",
    "# Function to query the localhost server\n",
    "def query_localhost(prompt):\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:1234/v1\", json={\"prompt\": prompt})\n",
    "        response.raise_for_status()  # Ensure we raise an error for bad responses\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {\"generated_text\": \"Error: Unable to process the request.\"}\n",
    "\n",
    "# Function to get an answer using RAG\n",
    "def get_rag_answer(question):\n",
    "    # Retrieve relevant document section (simulating the retrieval step)\n",
    "    relevant_answer = None\n",
    "    for entry in rag_data:\n",
    "        if question.lower() in entry['question'].lower():\n",
    "            relevant_answer = entry['answer']\n",
    "            break\n",
    "    \n",
    "    # Generate the final answer using the model\n",
    "    prompt = f\"Question: {question}\\n\\nAnswer: {relevant_answer if relevant_answer else ''}\"\n",
    "    generated_answer = query_localhost(prompt)\n",
    "    \n",
    "    return generated_answer.get(prompt, generated_answer)\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the capital of France?\"\n",
    "answer = get_rag_answer(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\chromadb\\__init__.py:86\u001b[0m\n\u001b[0;32m     84\u001b[0m             sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mYour system has an unsupported version of sqlite3. Chroma \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124m                    requires sqlite3 >= 3.35.0.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94mPlease visit \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124m                    https://docs.trychroma.com/troubleshooting#sqlite to learn how \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124m                    to upgrade.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m             )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "import chromadb\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader\n",
    "#from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\"loading model\")\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "fulldir = Path.home() / 'OneDrive' / 'Documents' / 'throawaylien'\n",
    "# C:\\Users\\joshs\\OneDrive\\Documents\\throawaylien\n",
    "#loaderTEXT = TextLoader(pathy)\n",
    "dirloader = DirectoryLoader(fulldir.absolute(), glob='**/*.txt', loader_cls=TextLoader)\n",
    "#loaderPDF = PyPDFLoader(pathypdf)\n",
    "print(\"instantiated loader\")\n",
    "dirdata = dirloader.load()\n",
    "\n",
    "# print(\"Data was: \", data)\n",
    "print(\"splitting text and embedding using gpt4all embeddings\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(dirdata)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"n/a\",\n",
    "    model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\",\n",
    "    # model=\"text-embedding-3-small\",\n",
    "    # embedding_ctx_length=1000,\n",
    "    # tiktoken_enabled=True,\n",
    "    )\n",
    "new_client = chromadb.EphemeralClient()\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "print(\"finished the vectorestore\")\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = client\n",
    "\n",
    "template = \"\"\"Use the provided pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Keep the answer as concise as possible.\n",
    "\n",
    "CONTEXT:\n",
    "\n",
    "```{context}```\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "HELPFUL ANSWER:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def enter_question():\n",
    "    print(\"about to invoke the rag_chain\")\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | custom_rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    question = input(\"Enter your prompt: \")\n",
    "    for chunk in rag_chain.stream(question):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    print(\"just finished invoking the rag_chain\")\n",
    "    # cleanup\n",
    "\n",
    "while True:\n",
    "    enter_question()\n",
    "\n",
    "vectorstore.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
