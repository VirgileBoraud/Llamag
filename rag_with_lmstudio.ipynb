{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.33.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arthu\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arthu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Query: What is the meaning of life?\n",
      "Answer: The first steps consists in defining the objective function you want to optimize. This is the most important step: you must define an experimentation which is reproducible and which will produce results that can be measured to approximate the function you want to optimize.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install openai pandas\n",
    "\n",
    "# Import necessary libraries\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(text, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "# Load the Q&A data\n",
    "with open('Q&A_format.md', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Manually split the document based on headers\n",
    "questions_answers = data.split(\"Question: \")\n",
    "\n",
    "# Process the split data into a structured format\n",
    "qa_pairs = []\n",
    "for qa in questions_answers[1:]:  # Skipping the first empty split\n",
    "    parts = qa.split(\"Answer: \")\n",
    "    question = parts[0].strip()\n",
    "    answer = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "    qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Get embeddings for questions\n",
    "df['question_embedding'] = df['question'].apply(lambda x: get_embedding(x))\n",
    "\n",
    "# Save the embeddings and QA pairs for future use\n",
    "df.to_csv('qa_embeddings.csv', index=False)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Function to find the most similar question\n",
    "def find_most_similar_question(query, df, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\"):\n",
    "    query_embedding = get_embedding(query, model)\n",
    "    df['similarity'] = df['question_embedding'].apply(lambda x: 1 - cosine(query_embedding, x))\n",
    "    most_similar_idx = df['similarity'].idxmax()\n",
    "    return df.iloc[most_similar_idx]\n",
    "\n",
    "# Function to get answer based on query\n",
    "def get_answer(query, df):\n",
    "    most_similar_qa = find_most_similar_question(query, df)\n",
    "    return most_similar_qa['answer']\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the meaning of life?\"\n",
    "answer = get_answer(query, df)\n",
    "print(f\"Query: {query}\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is classification?\n",
      "Answer: A classification task involves assigning input data to one of several predefined categories or classes. The goal is to predict the category to which new data points belong, based on the training data. Examples include identifying email as spam or not spam, classifying images of animals, or recognizing spoken words.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What is classification?\"\n",
    "answer = get_answer(query, df)\n",
    "print(f\"Query: {query}\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Canard?\n",
      "Answer: It's a method for demonstrating graphically the locality, spread and skewness groups of numerical data through their quartiles. In addition to the box, there can be lines (which are called whiskers) extending from the box indicating variability outside the upper and lower quartiles, thus, the plot is also called the box-and-whisker plot.\n"
     ]
    }
   ],
   "source": [
    "query = \"Canard?\"\n",
    "answer = get_answer(query, df)\n",
    "print(f\"Query: {query}\\nAnswer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
